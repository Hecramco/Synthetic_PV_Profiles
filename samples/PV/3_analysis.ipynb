{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, pickle, os, copy, sys, scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PROJECT_DIR = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "sys.path.insert(1, PROJECT_DIR)\n",
    "\n",
    "from utils_pv import *\n",
    "from samples.data_sim import PVDataset\n",
    "from feature_selection import tune_pacf, rfecv_selection\n",
    "from samples.data_sim import remove_feature\n",
    "\n",
    "random_seed = 3\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random_state = np.random.RandomState(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mahrokh/DECODE/Simulations/Synthetic_PV_Profiles/samples/PV/../../saved_results/PV_UniModal_env\n",
      "[INFO] loaded data for 24 clients\n",
      "\n",
      "24 households at Lausanne - tilt_std: 5.0, az_std: 15.0, weather_dev: 0.1, irrad_std: 0.2, altitude_dev: 0.1, shadow_peak_red: 0.8, different module_name, different inverter_name, \n",
      "sml has  50 train and 140 validation samples\n",
      "1y has 610 train and 140 validation samples\n",
      "5y has 3050 train and 140 validation samples\n",
      "15y has 9150 train and 140 validation samples\n",
      "number of features = 16\n"
     ]
    }
   ],
   "source": [
    "exp_name = 'PV_UniModal'\n",
    "filename_env = os.getcwd() + '/../../saved_results/' + exp_name + '_env' \n",
    "file = open(filename_env, 'rb')\n",
    "print(filename_env)\n",
    "env_dict = pickle.load(file)\n",
    "msg = '[INFO] loaded data for {:2.0f} clients'.format(env_dict['num_clients'])\n",
    "print(msg)\n",
    "file.close()\n",
    "print('\\n'+env_dict['info'])\n",
    "\n",
    "for scenario_name in env_dict['train_scenarios'].keys():\n",
    "    print(scenario_name + ' has {:3.0f} train and {:3.0f} validation samples'.format(\n",
    "                    env_dict['train_scenarios'][scenario_name]['clients_data'][0][0].shape[0],\n",
    "                    env_dict['train_scenarios'][scenario_name]['clients_data'][0][2].shape[0]))\n",
    "print('number of features = {:2.0f}'.format(\n",
    "                    env_dict['train_scenarios'][scenario_name]['clients_data'][0][0].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] reconstructed the 5y scenario.\n"
     ]
    }
   ],
   "source": [
    "# reconstruct houses\n",
    "from house_pv import reconstruct_house\n",
    "scenario_name_recons='5y'\n",
    "clients_subset = [12, 14, 15, 17, 22]\n",
    "houses = [None] * env_dict['num_clients']\n",
    "for client_num in clients_subset:\n",
    "    houses[client_num] = reconstruct_house(\n",
    "                            env_dict=env_dict, \n",
    "                            client_num=client_num, \n",
    "                            scenario_name=scenario_name_recons)\n",
    "print('[INFO] reconstructed the ' + scenario_name_recons + ' scenario.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: station irrad relevance and delay analysis\n",
    "Weather station direct and diffuse irradiation added to features of all houses\n",
    "* Irradiation measured at a weather station not at each house => economically feasible\n",
    "* Effect of including irradiation from weather station\n",
    "* Do lags add more information?\n",
    "    ** fit a linear model to 5 years of data, compare accuracies\n",
    "* Using irradiation at t to predict power at t+1 vs. \"predicted\" irradiation at t+1 to predict power at t+1\n",
    "    ** removing the need to another prediction model for the irradiation\n",
    "\n",
    "\n",
    "### Results:\n",
    "---------- LINEAR AND RIDGE REGRESSION WITHOUT GP ---------- <br>\n",
    "sml<br>\n",
    "with lags mean validation RMSE: 12.91 +/- 12.27<br>\n",
    "no lags mean validation RMSE: 20.64 +/- 19.00<br>\n",
    "no irradiation mean validation RMSE: 13.72 +/- 12.96<br>\n",
    "delayed irradiation mean validation RMSE: 13.02 +/- 12.39<br>\n",
    "1y<br>\n",
    "with lags mean validation RMSE: 11.55 +/- 11.19<br>\n",
    "no lags mean validation RMSE: 20.50 +/- 18.88<br>\n",
    "no irradiation mean validation RMSE: 12.69 +/- 12.00<br>\n",
    "delayed irradiation mean validation RMSE: 11.57 +/- 11.22<br>\n",
    "5y<br>\n",
    "with lags mean validation RMSE: 11.47 +/- 11.27<br>\n",
    "no lags mean validation RMSE: 20.43 +/- 18.93<br>\n",
    "no irradiation mean validation RMSE: 12.28 +/- 11.88<br>\n",
    "delayed irradiation mean validation RMSE: 11.50 +/- 11.30<br>\n",
    "15y<br>\n",
    "with lags mean validation RMSE: 11.48 +/- 11.28<br>\n",
    "no lags mean validation RMSE: 20.43 +/- 18.93<br>\n",
    "no irradiation mean validation RMSE: 12.23 +/- 11.70<br>\n",
    "delayed irradiation mean validation RMSE: 11.50 +/- 11.32<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_cell = False\n",
    "if run_cell:\n",
    "    from model_training.search_models import best_lin_reg\n",
    "    normalize_data=True\n",
    "    verbose=False\n",
    "\n",
    "    num_clients=24\n",
    "    city_names = ['Lausanne']\n",
    "    env_dict_with_lags = {'city_names':city_names,\n",
    "                'num_clients': num_clients, 'num_modes': len(city_names),\n",
    "                'tilt_std': 5, 'az_std':15, 'weather_dev':0.1,\n",
    "                'irrad_std':0.2, 'altitude_dev':0.1, 'shadow_peak_red':0.6,\n",
    "                'module_name': get_available_modules('sandia')[0:num_clients],\n",
    "                'inverter_name': get_available_inverters('cec')[0:num_clients],\n",
    "                'lags':None, 'months':[3,4], 'hours':np.arange(7, 17), \n",
    "                'years':np.arange(2014, 2020), # 5 years of data\n",
    "                'use_station_irrad_direct':True, 'use_station_irrad_diffuse':True,\n",
    "                'delay_irrad':False, # this env uses predicted irrad\n",
    "                'train_scenarios':{'sml':{'m_train':50, 'train_years':[2018], 'exclude_last_year':True},\n",
    "                                '1y':{'m_train':None, 'train_years':[2018], 'exclude_last_year':True},\n",
    "                                '5y':{'m_train':None, 'train_years':np.arange(2014, 2019), 'exclude_last_year':True},\n",
    "                                '15y':{'m_train':None, 'train_years':None, 'exclude_last_year':True}}}\n",
    "    env_dict_with_lags = PVDataset(env_dict_with_lags).generate_clients_data()\n",
    "\n",
    "    env_dict_no_lags = copy.deepcopy(env_dict_with_lags)\n",
    "    env_dict_no_irrad = copy.deepcopy(env_dict_with_lags)\n",
    "    env_dict_delayed = copy.deepcopy(env_dict_with_lags)\n",
    "\n",
    "    # features to keep \n",
    "    inds_to_keep_no_lags, inds_to_keep_no_irrad = [], []\n",
    "    for ind, feature_name in enumerate(env_dict_with_lags['feature_names']):\n",
    "        if not feature_name.startswith('lag'):\n",
    "            inds_to_keep_no_lags.append(ind)\n",
    "        if not feature_name.startswith('station_irrad'):\n",
    "            inds_to_keep_no_irrad.append(ind)\n",
    "    # features to delay for delayed irrads\n",
    "    cols_to_delay=[]\n",
    "    for ind, feature_name in enumerate(env_dict_delayed['feature_names']):\n",
    "        if feature_name.startswith('station_irrad'):\n",
    "            cols_to_delay.append(ind)\n",
    "\n",
    "    # only keep the selected features\n",
    "    for client_num in np.arange(env_dict_with_lags['num_clients']):\n",
    "        for scenario in env_dict_with_lags['train_scenarios']:\n",
    "            x_train, y_train, x_valid, y_valid = env_dict_with_lags['train_scenarios'][scenario]['clients_data'][client_num]\n",
    "            # no lags\n",
    "            x_train_no_lags = x_train[:, inds_to_keep_no_lags]\n",
    "            x_valid_no_lags = x_valid[:, inds_to_keep_no_lags]\n",
    "            env_dict_no_lags['train_scenarios'][scenario]['clients_data'][client_num] = (x_train_no_lags, y_train, x_valid_no_lags, y_valid)\n",
    "            # no irrad\n",
    "            x_train_no_irrad = x_train[:, inds_to_keep_no_irrad]\n",
    "            x_valid_no_irrad = x_valid[:, inds_to_keep_no_irrad]\n",
    "            env_dict_no_irrad['train_scenarios'][scenario]['clients_data'][client_num] = (x_train_no_irrad, y_train, x_valid_no_irrad, y_valid)\n",
    "            # delayed irrad\n",
    "            # NOTE: one less sample\n",
    "            x_train_dalayed, y_train_dalayed = x_train[1:, :], y_train[1:]\n",
    "            x_valid_dalayed, y_valid_dalayed = x_valid[1:, :], y_valid[1:]\n",
    "            x_train_dalayed[:, cols_to_delay] = x_train[:-1, cols_to_delay]\n",
    "            x_valid_dalayed[:, cols_to_delay] = x_valid[:-1, cols_to_delay]\n",
    "            env_dict_delayed['train_scenarios'][scenario]['clients_data'][client_num] = (x_train_dalayed, y_train_dalayed, \n",
    "                                                            x_valid_dalayed, y_valid_dalayed)\n",
    "\n",
    "\n",
    "    env_dict_no_lags['feature_names'] = [x for i, x in enumerate(env_dict_no_lags['feature_names']) if i in inds_to_keep_no_lags]\n",
    "    env_dict_no_irrad['feature_names'] = [x for i, x in enumerate(env_dict_no_irrad['feature_names']) if i in inds_to_keep_no_irrad]\n",
    "\n",
    "\n",
    "\n",
    "    print('\\n---------- LINEAR AND RIDGE REGRESSION ----------')\n",
    "    env_names = ['with lags', 'no lags', 'no irradiation', 'delayed irradiation']\n",
    "    envs = [env_dict_with_lags, env_dict_no_lags, env_dict_no_irrad, env_dict_delayed]\n",
    "    for scenario_name in env_dict_with_lags['train_scenarios'].keys():\n",
    "        print(scenario_name)\n",
    "        for env_tmp, env_name in zip(envs, env_names):\n",
    "            # Linear regression without GP\n",
    "            valid_rmses_linreg = np.zeros(num_clients)\n",
    "            for client_num in np.arange(num_clients):\n",
    "                if verbose:\n",
    "                    print('\\nClient {:2.0f}'.format(client_num))\n",
    "                _, valid_rmses_linreg[client_num] = best_lin_reg(clients_data=env_tmp['train_scenarios'][scenario_name]['clients_data'], \n",
    "                            client_num=client_num, logger=None, normalize_data=normalize_data, verbose=verbose) \n",
    "\n",
    "            print(env_name + ' mean validation RMSE: {:2.2f} +/- {:.2f}'.format(np.mean(valid_rmses_linreg),\n",
    "                                                                    1.96*np.std(valid_rmses_linreg)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Checking modelling assumptions\n",
    "* multicollinearity\n",
    "* is data from each house homogeneous and i.i.d?\n",
    "* are houses independent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "for train_scenario in env_dict['train_scenarios'].keys():\n",
    "    print('\\n Train scenario: ', train_scenario)\n",
    "    # VIF dataframe\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = env_dict['feature_names']\n",
    "    for client_num in np.arange(num_clients):\n",
    "        # get train data\n",
    "        X_train = env_dict['train_scenarios'][train_scenario]['clients_data'][client_num][0]\n",
    "\n",
    "        # calculating VIF for each feature\n",
    "        vif_data[str(client_num)] = [variance_inflation_factor(X_train, i)\n",
    "                                for i in range(len(env_dict['feature_names']))]\n",
    "\n",
    "    vif_data[\"average\"] = vif_data.mean(axis=1)\n",
    "    print(vif_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Checking Modelling Assumptions\n",
    "* multicollinearity\n",
    "* is data from each house homogeneous and i.i.d?\n",
    "* are houses independent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "for train_scenario in env_dict['train_scenarios'].keys():\n",
    "    print('\\n Train scenario: ', train_scenario)\n",
    "    # VIF dataframe\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = env_dict['feature_names']\n",
    "    for client_num in np.arange(num_clients):\n",
    "        # get train data\n",
    "        X_train = env_dict['train_scenarios'][train_scenario]['clients_data'][client_num][0]\n",
    "\n",
    "        # calculating VIF for each feature\n",
    "        vif_data[str(client_num)] = [variance_inflation_factor(X_train, i)\n",
    "                                for i in range(len(env_dict['feature_names']))]\n",
    "\n",
    "    vif_data[\"average\"] = vif_data.mean(axis=1)\n",
    "    print(vif_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Measuring Heterogeneity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('py3.9.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3e2ee8da2af4f50ba4f3c8ab2659ba411444dacb49c19d05c5f3f92ad54a0395"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
